from sklearn.metrics import roc_auc_score
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
y_true = [
    0,
    1,
    1,
    0,
    1
]

y_predictions = [
    0.1,
    0.9,
    0.4,
    0.6,
    0.61
]

roc_auc_score(y_true, y_predictions)
data = pd.read_csv('./train.csv')
# Числовые признаки
num_cols = [
    'ClientPeriod',
    'MonthlySpending',
    'TotalSpent'
]

# Категориальные признаки
cat_cols = [
    'Sex',
    'IsSeniorCitizen',
    'HasPartner',
    'HasChild',
    'HasPhoneService',
    'HasMultiplePhoneNumbers',
    'HasInternetService',
    'HasOnlineSecurityService',
    'HasOnlineBackup',
    'HasDeviceProtection',
    'HasTechSupportAccess',
    'HasOnlineTV',
    'HasMovieSubscription',
    'HasContractPhone',
    'IsBillingPaperless',
    'PaymentMethod'
]

feature_cols = num_cols + cat_cols
target_col = 'Churn'
data = data.convert_dtypes()
data.dtypes
print("Возможные значения IsSeniorCitizen до преобразования:\n")
print(data['IsSeniorCitizen'].value_counts())
data['IsSeniorCitizen'] = data['IsSeniorCitizen'].astype('object')
data.loc[data['IsSeniorCitizen'] == 1, 'IsSeniorCitizen'] = 'Yes'
data.loc[data['IsSeniorCitizen'] == 0, 'IsSeniorCitizen'] = 'No'
data['IsSeniorCitizen'] = data['IsSeniorCitizen'].astype('string')
print("\nВозможные значения IsSeniorCitizen после преобразования:\n")
print(data['IsSeniorCitizen'].value_counts())
print("\nТипы после преобразования:")
data.dtypes
try:
    data['TotalSpent'] = data['TotalSpent'].astype('float64')
except ValueError as e:
    print("С данными что-то не то:", e)
    import re
import numpy as np

def check_for_empy_strings(df):
    df.applymap(lambda x: bool(re.match(r"^\s*$", str(x)))).any(axis=None)

tested_cols = ['TotalSpent'] + cat_cols
flag = check_for_empy_strings(data[tested_cols])
print("Отсутствующие данные в виде пустых и пробельных строк:", "есть" if flag else "нет")
table = data.isna().sum()
print("Количество nan по колонкам:", table, sep="\n\n")
print("\nПропуски в данных:", "нет" if (table == 0).all() else "есть")
print("Список колонок, в которых есть пропуски:", ', '.join(table[table != 0].index))
%matplotlib inline
import matplotlib.pyplot as plt

col_labels = ["Длительность в месяцах", "Траты в месяц", "Всего потрачено"]
subplots_shape = (2, 2)
fig = plt.figure(figsize=(14, 12))
fig.suptitle("Гистограммы числовых признаков", fontweight="bold", fontsize=20)
for i, (col, xlabel) in enumerate(zip(num_cols, col_labels), 1):
    ax = plt.subplot(*subplots_shape, i)
    ax.set_title(col, fontsize=16, fontweight="bold")
    ax.set_xlabel(xlabel)
    ax.set_ylabel("Количество клиентов")
    data.hist(column=col, ax=ax, bins=20, grid=False)
    fit = plt.figure(figsize=(14, 12))
fig.suptitle("Диаграммы размаха числовых признаков", fontweight="bold", fontsize=20)

for i, (col, ylabel) in enumerate(zip(num_cols, col_labels), 1):
    ax = plt.subplot(*subplots_shape, i)
    ax.set_title(col, fontsize=16, fontweight="bold")
    ax.set_ylabel(ylabel)
    data.boxplot(column=col, ax=ax)
    for col in cat_cols:
    print("Количество значений категориального признака {}:\n".format(col))
    print(data[col].value_counts())
    print()
    cat_cols_num = len(cat_cols)
cells_by_horizontal = min(4, int(np.ceil(np.sqrt(cat_cols_num))))
cells_by_vertical = int(np.ceil(cat_cols_num / cells_by_horizontal))
subplots_shape = (cells_by_vertical, cells_by_horizontal)
fig = plt.figure(figsize=(7 * cells_by_horizontal , 6 * cells_by_vertical))
fig.suptitle("Гистограммы количества разных значений категориальных признаков", fontweight="bold", fontsize=20)

for i, col in enumerate(cat_cols, 1):
    ax = plt.subplot(*subplots_shape, i)
    ax.set_title(col, fontsize=16, fontweight="bold")
    
    data[col].value_counts().plot.bar(rot=10)
    fig = plt.figure(figsize=(7 * cells_by_horizontal , 6 * cells_by_vertical))
fig.suptitle("Круговые диаграммы количества разных значений категориальных признаков", fontweight="bold", fontsize=20)

for i, col in enumerate(cat_cols, 1):
    ax = plt.subplot(*subplots_shape, i)
    ax.set_title(col, fontsize=16, fontweight="bold")
    
    data[col].value_counts().plot.pie(ax=ax, autopct='%1.1f%%')
    ax.set_ylabel(None)
    tvc = data[target_col].value_counts()
tvc.plot.bar(title=target_col);
tol = 0.2
target_class_percentage = tvc.loc[1] / sum(tvc)
print("Вывод: классы", "" if abs(target_class_percentage - 0.5) < tol else "не", "сбалансированы")
import seaborn as sns
sns.pairplot(data, hue=target_col);
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.pipeline import make_pipeline
nan_rows_num = data.apply(lambda row: row.isnull().any(), axis=1, raw=False).sum()
print("Доля строк с NaN:", nan_rows_num / len(data))
print("Количество строк в датасете\n\tдо удаления NaN:", len(data))
data = data.dropna()
print("\tпосле удаления NaN:", len(data))
X, y = data[feature_cols], data[target_col]
class DataTransformer:
    def __init__(self, num_cols, cat_cols, drop=None):
        self.num_cols = num_cols
        self.cat_cols = cat_cols
        self._scaler = StandardScaler()
        self._one_hot_encoder = OneHotEncoder(sparse=False, drop=drop)

    def clear_data(self, data):
        data.loc[data['IsSeniorCitizen'] == 1, 'IsSeniorCitizen'] = 'Yes'
        data.loc[data['IsSeniorCitizen'] == 0, 'IsSeniorCitizen'] = 'No'
        data = data.convert_dtypes()
        data['TotalSpent'] = pd.to_numeric(data['TotalSpent'], errors='coerce')
        data = data.fillna(data.mean())
        return data

    def fit(self, data, target=None):
        data = self.clear_data(data)
        self._scaler.fit(data[self.num_cols]) 
        self._one_hot_encoder.fit(data[self.cat_cols])

    def transform(self, data, target=None):
        data = self.clear_data(data)
        scaled_num_cols = self._scaler.transform(data[self.num_cols])
        encoded_cat_cols = self._one_hot_encoder.transform(data[self.cat_cols])
        return np.hstack((scaled_num_cols, encoded_cat_cols))

    def fit_transform(self, data, target=None):
        data = self.clear_data(data)
        scaled_num_cols = self._scaler.fit_transform(data[self.num_cols])
        encoded_cat_cols = self._one_hot_encoder.fit_transform(data[self.cat_cols])
        return np.hstack((scaled_num_cols, encoded_cat_cols))

from sklearn.pipeline import Pipeline
clsf = Pipeline(steps=[('datatransformer', DataTransformer(num_cols, cat_cols, drop='first')), ('logistic', LogisticRegression(random_state=42))])

from sklearn.metrics import make_scorer
from sklearn.model_selection import StratifiedKFold

grid_search = GridSearchCV(clsf, param_grid={'logistic__C': [100, 10, 1, 0.1, 0.01, 0.001]},
                               cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=make_scorer(roc_auc_score), n_jobs=-1,
                               verbose=10)
X, y = data[feature_cols], data[target_col].astype('int8')
grid_search.fit(X, y)
GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('datatransformer',
                                        <__main__.DataTransformer object at 0x000001D32BC03880>),
                                       ('logistic',
                                        LogisticRegression(random_state=42))]),
             n_jobs=-1,
             param_grid={'logistic__C': [100, 10, 1, 0.1, 0.01, 0.001]},
             scoring=make_scorer(roc_auc_score), verbose=10)
import catboost

categorical_indices = list(X.columns.get_loc(col) for col in cat_cols)
X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, train_size=0.8, random_state=42)
boosting_model = catboost.CatBoostClassifier(n_estimators=200, cat_features=categorical_indices)
boosting_model.fit(X_train, y_train)
y_test_predicted = boosting_model.predict_proba(X_test)[:, 1]
print("\nКачество при стандартных параметрах:", roc_auc_score(y_test, y_test_predicted))
boosting_model = catboost.CatBoostClassifier(n_estimators=200,
                                             cat_features=categorical_indices,
                                             eval_metric='AUC')
grid = {'learning_rate': [0.03, 0.1],
        'depth': [4, 6, 10],
        'l2_leaf_reg': [1, 3, 5, 7, 9]}
boosting_grid_search_res = boosting_model.grid_search(grid, 
                           X.values, 
                           y.values, train_size=0.8, cv=5, plot=False, verbose=10, refit=True)
                           boosting_model = catboost.CatBoostClassifier(**boosting_grid_search_res['params'], n_estimators=200,
                                             cat_features=categorical_indices,
                                             eval_metric='AUC')
boosting_model.fit(X_train, y_train)
y_test_predicted = boosting_model.predict_proba(X_test)[:, 1]
test_auc = roc_auc_score(y_test, y_test_predicted)
print("Лучшее качество: {} с параметрами {}".format(test_auc, boosting_grid_search_res['params']))best_model = boosting_model
best_model.predict_proba(X_test)[:, 1]
array([0.03947285, 0.6108774 , 0.66218428, ..., 0.79052441, 0.53489933,
       0.02381376])
X_test = pd.read_csv('./test.csv')
# submission = pd.read_csv('./submission.csv')

predicted_labels = best_model.predict_proba(X_test)[:, 1]
df = pd.DataFrame({'Churn': predicted_labels}, index=np.arange(len(predicted_labels)))
df.index.name = 'Id'
df.to_csv('./my_submission.csv')
